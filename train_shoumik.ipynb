{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import magic\n",
    "from secml.array import CArray\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from secml_malware.models.malconv import MalConv\n",
    "from secml_malware.models.c_classifier_end2end_malware import CClassifierEnd2EndMalware, End2EndModel\n",
    "#import secml_malware.models.c_classifier_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = MalConv()\n",
    "net = CClassifierEnd2EndMalware(net)\n",
    "#path = \"secml_malware/data/trained/test_malconv.pth\"\n",
    "net.load_pretrained_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "folder = \"secml_malware/data/malware_samples/test_folder\"\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "file_names = []\n",
    "for i, f in enumerate(os.listdir(folder)):\n",
    "    #print(f)\n",
    "    path = os.path.join(folder, f)\n",
    "    \"\"\"\n",
    "    if 'petya' not in path:\n",
    "        continue\n",
    "    if \"PE32\" not in magic.from_file(path):\n",
    "        continue\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as file_handle:\n",
    "        code = file_handle.read()\n",
    "    x = End2EndModel.bytes_to_numpy(\n",
    "        code, net.get_input_max_length(), 256, False\n",
    "    )\n",
    "    #y_train = np.ones((x.shape[0]))\n",
    "    #print(x, y_train)\n",
    "    #print(x.shape)\n",
    "\n",
    "    X.append(x)\n",
    "    y.append([1.0])\n",
    "    file_names.append(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "folder = \"secml_malware/data/goodware_samples/my_samples\"\n",
    "for i, f in enumerate(os.listdir(folder)):\n",
    "    #print(f)\n",
    "    path = os.path.join(folder, f)\n",
    "    \"\"\"\n",
    "    if 'petya' not in path:\n",
    "        continue\n",
    "    if \"PE32\" not in magic.from_file(path):\n",
    "        continue\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as file_handle:\n",
    "        code = file_handle.read()\n",
    "    x = End2EndModel.bytes_to_numpy(\n",
    "        code, net.get_input_max_length(), 256, False\n",
    "    )\n",
    "    #y_train = np.ones((x.shape[0]))\n",
    "    #print(x, y_train)\n",
    "    #print(x.shape)\n",
    "\n",
    "    X.append(x)\n",
    "    y.append([0.0])\n",
    "    file_names.append(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "CArray([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.])\n"
     ]
    }
   ],
   "source": [
    "input_X = CArray(X)\n",
    "#input_y = CArray(y)\n",
    "y = torch.FloatTensor(y)\n",
    "#y = torch.unsqueeze(y, 1)\n",
    "y = torch.reshape(y, (-1, ))\n",
    "input_y = CArray(y)\n",
    "print(input_y.shape)\n",
    "print(input_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CClassifierEnd2EndMalware{'classes': array([0, 1]), 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': False, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}\n",
      "CClassifierEnd2EndMalware{'classes': array([0, 1]), 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': False, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 2, 'plus_version': False, 'train_transform': Lambda()}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "print(net)\n",
    "net2 = copy.deepcopy(net)\n",
    "net2.epochs = 2\n",
    "print(net2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CClassifierEnd2EndMalware{'classes': CArray(2,)(dense: [0. 1.]), 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': True, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 2, 'plus_version': False, 'train_transform': Lambda()}\n",
      "CClassifierEnd2EndMalware{'classes': CArray(2,)(dense: [0. 1.]), 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': True, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 2, 'plus_version': False, 'train_transform': Lambda()}\n"
     ]
    }
   ],
   "source": [
    "new_model = net2.fit(input_X, input_y)\n",
    "print(net2)\n",
    "net2._model = new_model\n",
    "print(net2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CArray([1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0])\n"
     ]
    }
   ],
   "source": [
    "print(net2.predict(input_X))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CArray([1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0])\n"
     ]
    }
   ],
   "source": [
    "print(net.predict(input_X))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "torch.save(net2._model.state_dict(), 'secml_malware/data/trained/test_malconv.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, I will try to divide the input into number of ablations and pass them to the 'vanilla' MalConv model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1048576) [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "num_ablations = 4\n",
    "max_input_size = 2**20\n",
    "ablation_size = int(max_input_size/num_ablations)\n",
    "padding_value = 256\n",
    "new_X = []\n",
    "new_Y = []\n",
    "for i, x in enumerate(X):\n",
    "    #print(i, x)\n",
    "    splitted_x_array = np.split(x, num_ablations)\n",
    "    for j, splitted_x in enumerate(splitted_x_array):\n",
    "        byte_array = np.ones((max_input_size,), dtype=np.int16) * padding_value\n",
    "        byte_array[j*ablation_size : (j+1)*ablation_size] = splitted_x\n",
    "        new_X.append(byte_array)\n",
    "    new_Y.append(np.ones((num_ablations)) if y[i]==1 else np.zeros((num_ablations)))\n",
    "new_X = np.asarray(new_X)\n",
    "#new_X = np.reshape(new_X, (-1, 1))\n",
    "new_Y = np.asarray(new_Y)\n",
    "print(new_X.shape, new_Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1048576)\n",
      "CArray([[ 77.  90. 144. ... 256. 256. 256.]\n",
      " [256. 256. 256. ... 256. 256. 256.]\n",
      " [256. 256. 256. ... 256. 256. 256.]\n",
      " ...\n",
      " [256. 256. 256. ... 256. 256. 256.]\n",
      " [256. 256. 256. ... 256. 256. 256.]\n",
      " [256. 256. 256. ... 256. 256. 256.]]) CArray([[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]])\n"
     ]
    }
   ],
   "source": [
    "new_X = torch.FloatTensor(new_X)\n",
    "#new_X = torch.reshape(new_X, (new_X.shape[0] * new_X.shape[1], new_X.shape[2]))\n",
    "input_X = CArray(new_X)\n",
    "print(input_X.shape)\n",
    "new_Y = torch.FloatTensor(new_Y)\n",
    "new_Y = torch.reshape(new_Y, (-1, 1))\n",
    "input_Y = CArray(new_Y)\n",
    "print(input_X, input_Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "y_pred = net2.predict(input_X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5875\n"
     ]
    }
   ],
   "source": [
    "from secml.ml.peval.metrics import CMetric\n",
    "peval = CMetric.create('accuracy')\n",
    "print(peval.performance_score(input_Y, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, I will try to create multiple MalConv models for different ablations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "num_ablations = 5\n",
    "max_input_size = 2**20-1\n",
    "ablation_size = int(max_input_size/num_ablations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "net = MalConv(max_input_size = ablation_size)\n",
    "net = CClassifierEnd2EndMalware(net, input_shape = (1, ablation_size))\n",
    "net._n_features = ablation_size\n",
    "#net.load_pretrained_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CClassifierEnd2EndMalware{'classes': None, 'n_features': 209715, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': False, 'input_shape': (1, 209715), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}, CClassifierEnd2EndMalware{'classes': None, 'n_features': 209715, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': False, 'input_shape': (1, 209715), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}, CClassifierEnd2EndMalware{'classes': None, 'n_features': 209715, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': False, 'input_shape': (1, 209715), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}, CClassifierEnd2EndMalware{'classes': None, 'n_features': 209715, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': False, 'input_shape': (1, 209715), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}, CClassifierEnd2EndMalware{'classes': None, 'n_features': 209715, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': False, 'input_shape': (1, 209715), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}]\n"
     ]
    }
   ],
   "source": [
    "nets = []\n",
    "for i in range(num_ablations):\n",
    "    net = MalConv(max_input_size = ablation_size)\n",
    "    net = CClassifierEnd2EndMalware(net, input_shape = (1, ablation_size))\n",
    "    net._n_features = ablation_size\n",
    "    nets.append(net)\n",
    "print(nets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 5, 209715)\n",
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "new_X = []\n",
    "new_Y = []\n",
    "for i, x in enumerate(X):\n",
    "    splitted_x_array = np.split(x[:-1], num_ablations)  ##here, -1 to make it divisible of 5\n",
    "    new_X.append(splitted_x_array)\n",
    "    new_Y.append(np.ones((num_ablations)) if y[i]==1 else np.zeros((num_ablations)))\n",
    "new_X = np.asarray(new_X)\n",
    "new_Y = np.asarray(new_Y)\n",
    "print(new_X.shape)\n",
    "print(new_Y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5, 209715])\n",
      "CArray([[ 77.  90. 144. ... 256. 256. 256.]\n",
      " [ 77.  90. 144. ... 256. 256. 256.]\n",
      " [ 77.  90. 144. ... 256. 256. 256.]\n",
      " ...\n",
      " [ 77.  90. 144. ... 256. 256. 256.]\n",
      " [ 77.  90. 144. ... 256. 256. 256.]\n",
      " [ 77.  90. 144. ... 256. 256. 256.]]) CArray([[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]])\n"
     ]
    }
   ],
   "source": [
    "new_X = torch.FloatTensor(new_X)\n",
    "#new_X = torch.reshape(new_X, (new_X.shape[0] * new_X.shape[1], new_X.shape[2]))\n",
    "print(new_X.shape)\n",
    "#input_X = CArray(new_X, copy=True, shape=(new_X.shape[0], new_X.shape[1], new_X.shape[2]), tosparse=False)\n",
    "#print(input_X.shape)\n",
    "new_Y = torch.FloatTensor(new_Y)\n",
    "#new_Y = torch.reshape(new_Y, (-1, 1))\n",
    "input_Y = CArray(new_Y)\n",
    "print(input_X, input_Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "for i in range(len(nets)):\n",
    "    nets[i].epochs = 5\n",
    "    nets[i]._model = nets[i].fit(new_X[:, i, :], new_Y[:, i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "for i in range(len(nets)):\n",
    "    y_pred = nets[i].predict(new_X[:, i, :])\n",
    "    #print(y_pred)\n",
    "    y_preds.append(y_pred.tondarray())\n",
    "y_preds = np.asarray(y_preds)\n",
    "print(y_preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.8 0.2 0.4 1.  0.4 0.2\n",
      " 0.4 0.8]\n",
      "Accuracy without majority voting:  0.8099999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "preds_acc_perc = []\n",
    "for i in range(new_Y.shape[0]):\n",
    "    preds_acc_perc.append(accuracy_score(new_Y[i, :], y_preds[:, i]))\n",
    "preds_acc_perc = np.asarray(preds_acc_perc)\n",
    "print(preds_acc_perc)\n",
    "print(\"Accuracy without majority voting: \", np.mean(preds_acc_perc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "def get_majority_voting(y_detailed, sample_no):\n",
    "    votes = []\n",
    "    for i in range(sample_no):\n",
    "        y_per_sample = y_detailed[:, i]\n",
    "        mal_vote = np.count_nonzero(y_per_sample)\n",
    "        ben_vote = np.count_nonzero(y_per_sample==0)\n",
    "        if(mal_vote >= ben_vote): votes.append(1)\n",
    "        else: votes.append(0)\n",
    "\n",
    "    return votes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0]\n",
      "Accuracy with majority voting:  0.75\n"
     ]
    }
   ],
   "source": [
    "votes = get_majority_voting(y_preds, len(y))\n",
    "print(votes)\n",
    "print(\"Accuracy with majority voting: \", accuracy_score(y, votes))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try to pass smaller input to the original MalConv model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "net = MalConv()\n",
    "net = CClassifierEnd2EndMalware(net)\n",
    "net.load_pretrained_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CClassifierEnd2EndMalware{'classes': array([0, 1]), 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      "), 'trained': False, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7faa12db7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from secml_malware.smoothed_malconv import get_dataset, create_smoothed_malconv, modify_dataset_for_smoothed_malconv, pad_ablated_input, train_model, model_predict, get_majority_voting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "mal_path = \"/Users/shoumik/Desktop/UMD 1st semester/Computer & Network Security/Project/Codes/MalConv-New/FullDataset/output/malware\"\n",
    "ben_path = \"/Users/shoumik/Desktop/UMD 1st semester/Computer & Network Security/Project/Codes/MalConv-New/FullDataset/output/benign\"\n",
    "X, y, file_names = get_dataset(mal_path, ben_path, 2**16, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65536,)\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "net._epochs = 2\n",
    "new_model = net._model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(new_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 524])\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "test_ipt = Variable(torch.zeros(1, 2**18))\n",
    "#embedding = new_model.embedding_1(test_ipt)\n",
    "embedding = net.embed(test_ipt)\n",
    "conv1d_1 = new_model.conv1d_1(embedding)\n",
    "conv1d_2 = new_model.conv1d_2(embedding)\n",
    "conv1d_1_activation = torch.relu(conv1d_1)\n",
    "conv1d_2_activation = torch.sigmoid(conv1d_2)\n",
    "multiply_1 = conv1d_1_activation * conv1d_2_activation\n",
    "global_max_pooling1d_1 = torch.nn.functional.max_pool1d(input=multiply_1, kernel_size=multiply_1.size()[2:])\n",
    "global_max_pooling1d_1_flatten = global_max_pooling1d_1.view(global_max_pooling1d_1.size(0), -1)\n",
    "\n",
    "print(multiply_1.shape)\n",
    "print(global_max_pooling1d_1_flatten.size(1))\n",
    "#print(global_max_pooling1d_1_flatten)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /Users/shoumik/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0.00/507M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39cb4e475e774e1ebd16a17621afaec0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg_loader = torchvision.models.vgg11\n",
    "vgg = vgg_loader(pretrained=True)\n",
    "print(vgg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Here, I will try to use the custom malconv model that has trainable fully connected layer**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from secml_malware.custom_malconv import Custom_MalConv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "net = Custom_MalConv(max_input_size=2**20, unfreeze=True)\n",
    "net = CClassifierEnd2EndMalware(net)\n",
    "net._n_features = 2**20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CClassifierEnd2EndMalware{'classes': None, 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': Custom_MalConv(\n",
      "  (embedding_1): Embedding(257, 8)\n",
      "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      "), 'trained': False, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': <function binary_cross_entropy at 0x7fba992d7af0>, 'optimizer': SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.001\n",
      "), 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n"
     ]
    }
   ],
   "source": [
    "mal_path = \"/Users/shoumik/Desktop/UMD 1st semester/Computer & Network Security/Project/Codes/MalConv-New/FullDataset/output/malware\"\n",
    "ben_path = \"/Users/shoumik/Desktop/UMD 1st semester/Computer & Network Security/Project/Codes/MalConv-New/FullDataset/output/benign\"\n",
    "X, y, file_names = get_dataset(mal_path, ben_path, 2 ** 20, 20)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 4, 262144) (40, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "[[[ 77.  90. 144. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]]\n",
      "\n",
      " [[ 77.  90. 144. ... 160.  53. 250.]\n",
      "  [204. 109.  69. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]]\n",
      "\n",
      " [[ 77.  90. 144. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 77.  90. 144. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]]\n",
      "\n",
      " [[ 77.  90. 144. ... 235.  26.  80.]\n",
      "  [232. 223.  60. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]]\n",
      "\n",
      " [[ 77.  90. 144. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]\n",
      "  [256. 256. 256. ... 256. 256. 256.]]]\n"
     ]
    }
   ],
   "source": [
    "new_X, new_y = modify_dataset_for_smoothed_malconv(X, np.reshape(y, (-1)), 4)\n",
    "print(new_X.shape, new_y.shape)\n",
    "print(type(new_X))\n",
    "print(new_X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144,)\n",
      "(40, 1048576)\n",
      "[[ 77.  90. 144. ... 256. 256. 256.]\n",
      " [ 77.  90. 144. ... 256. 256. 256.]\n",
      " [ 77.  90. 144. ... 256. 256. 256.]\n",
      " ...\n",
      " [ 77.  90. 144. ... 256. 256. 256.]\n",
      " [ 77.  90. 144. ... 256. 256. 256.]\n",
      " [ 77.  90. 144. ... 256. 256. 256.]]\n"
     ]
    }
   ],
   "source": [
    "print(new_X[0, 0, :].shape)\n",
    "new_padded_X = []\n",
    "ablation_idx = 0\n",
    "for i in range(new_X.shape[0]):\n",
    "    temp_X = pad_ablated_input(new_X[i, ablation_idx, :], ablation_idx)\n",
    "    new_padded_X.append(temp_X)\n",
    "new_padded_X = np.asarray(new_padded_X)\n",
    "print(new_padded_X.shape)\n",
    "print(new_padded_X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1048576) (16, 1048576)\n",
      "(24, 4)\n",
      "[[1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_padded_X, new_y, test_size=0.40, random_state=1)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#out = net.embedd_and_forward(net.embed(torch.FloatTensor(X)))\n",
    "#y = np.reshape(y, (-1))\n",
    "print(new_y)\n",
    "net._epochs = 2\n",
    "out = net.fit(x_train, y_train[:, ablation_idx])\n",
    "#out = net.fit(x_train[:, ablation_idx, :], y_train[:, ablation_idx])\n",
    "print(out)\n",
    "#net.fit(torch.FloatTensor(X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net._model = out\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = net.predict(CArray(x_train))\n",
    "#preds = net.predict(CArray(x_train[:, ablation_idx, :]))\n",
    "print(preds)\n",
    "accuracy_score(preds.tondarray(), y_train[:, ablation_idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = net.predict(CArray(x_test))\n",
    "#preds = net.predict(CArray(x_test[:, ablation_idx, :]))\n",
    "print(preds)\n",
    "accuracy_score(preds.tondarray(), y_test[:, ablation_idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
